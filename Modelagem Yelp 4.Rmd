---
title: "Integradora Yelp"
author: "Marcelo Francheschini, Rafael Costa, Viviane Sanchez"
date: "6/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(tidymodels)
library(tidytext)
library(skimr)
library(ggrepel)
library(ggdendro)
library(factoextra)
library(vip)
library(doParallel)
library(cluster)
library(plotly)

```

```{r}

library(tidytext)
library(tm)
library(wordcloud)
library(topicmodels)
library(drlib)
library(quanteda)
library(stm)

library(keras)
library(reticulate)

```

# Leitura de arquivos

```{r eval=FALSE, include=FALSE}

yelp_bz_raw <- list.files(path = 'output/yelp_bz.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

yelp_users <- list.files(path = 'output/yelp_usr.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

```

# Business

Clusterização dos estabelecimentos por semelhança de atributos


```{r}

glimpse(yelp_bz_raw)

yelp_bz <- yelp_bz_raw %>% 
          select_if(~is.numeric(.))
  
```

## Matriz de dissimilaridades

Distância Euclidiana é válida para intervalos contínuos. Como a base possui diferentes atributos, será utilizada a distância de Gower, que é mais apropriada para dados misturados

```{r}

bz_gower <- daisy(yelp_bz, metric = 'gower')

gower_mat <- as.matrix(bz_gower)

dim(gower_mat)

# Output most similar pair
#yelp_bz[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]),arr.ind = TRUE)[1, ], ]

# Output most dissimilar pair
#yelp_bz[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]

```

## MDS (lento)

```{r}

mds <- cmdscale(gower_mat, k = 35, eig = TRUE)

?cmdscale

barplot(mds$eig)

cumsum(mds$eig) / sum(mds$eig)

# ggplot(mapping = aes(x = factor(1:length(mds$eig)), y = mds$eig)) +
#     geom_col() +
#     labs(x = "", y = "")

hc <- hclust(dist(mds$points[, 1:2]))

ggdendrogram(hc, rotate = TRUE, size = 2, labels = TRUE) +
    labs(title = "Concorrência no mercado automobilístico")

cutree(hc, k = 3)



```


## HCLUST

```{r}
## Hclust

bz_hclust <- hclust(bz_gower)

clust <- cutree(hclust, k = 30)

ggdendrogram(hclust, rotate = TRUE, labels = TRUE) +
    labs(title = "Categorias em Toronto - Gower")

fviz_dend(hclust, cex = 0.5, k = 5,
          main = "Categorias em Toronto - Euclidiana",
          color_labels_by_k = TRUE, horiz = TRUE)


yelp_bz_clust <- yelp_bz_raw %>% 
                mutate(cluster = clust)


yelp_bz_clust %>% 
  ggplot(aes(longitude,latitude, color = cluster)) +
           geom_point()

```


## PCA

```{r}

yelp_bz_pca <-  yelp_bz_raw %>% 
                select_if(~is_numeric(.))
  
rec_pca <- recipe(stars ~ ., yelp_bz_pca) %>% 
  update_role(contains('id'), new_role = 'id') %>% 
  #step_date(date_rv, yelping_since_usr, features = c("dow", "month","year")) %>% 
  #step_other(categories, threshold = 0.005) %>% 
  #step_other(postal_code, threshold = 0.01) %>% 
  #step_dummy(all_nominal(), -'business_id',-'user_id',-'name_bz') %>%
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_pca(all_numeric(), -all_outcomes()) %>% 
  step_naomit(all_numeric()) %>% 
  prep()

yelp_bz_pca <- juice(rec_pca)

```


```{r}

variance_pct <- rec_pca$steps[[2]]$res

(cumsum(variance_pct$sdev^2) / sum(variance_pct$sdev^2))

fviz_eig(variance_pct, addlabels = TRUE) + 
  labs(x = "Componente Principal",
       y = "Percentual explicado da variância")

```


```{r}

tidy_pca <- tidy(rec_pca, 2)

tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(5, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Valor absoluto da contribuição",
    y = NULL, fill = "Positiva?")

variance_pct %>% 
  fviz_pca_var(axes = c(1,2), col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

pca_cols <- tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(1, abs(value)) %>%
  ungroup() %>% 
  select(terms) %>% 
  as.vector()

```

## K-means

```{r}

glimpse(yelp_bz_raw)

?kmeans

skim(yelp_bz)

set.seed(123)

kclusts <- tibble(k = 1:30) %>%
  mutate(kclust = map(k, ~kmeans(yelp_bz, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_bz)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))


#cotovelo
clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:30)


#k-means
assignments %>% 
  ggplot(aes(x = longitude, y = latitude)) +
  geom_point(aes(color = .cluster), alpha = 0.5) + 
  facet_wrap(~ k)

```


```{r}

set.seed(123)
kmeans_bz <-  kmeans(yelp_bz, 15)

yelp_bz_cluster <- yelp_bz_raw %>% 
          select(business_id) %>% 
          mutate(cluster = kmeans_bz$cluster)

yelp_bz_cluster

write.csv(yelp_bz_cluster, file = "output/bz_cluster.csv")

```

## HCLUST

```{r}


```

# Users
## KMeans
```{r}

yelp_usr_euc <- t(yelp_usr_raw[,-c(1)])

euc_usr_hclust <- (hclust(get_dist(t(yelp_usr_euc), method = 'euclidean')))

```

```{r}

set.seed(123)

yelp_pad <- yelp_users %>% 
              select(-user_id) %>% 
              scale() 

kclusts <- tibble(k = 1:20) %>%
  mutate(kclust = map(k, ~kmeans(yelp_pad, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_pad)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))

clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:20)


```


```{r}

set.seed(123)
kmeans_usr <-  kmeans(yelp_pad, 7)

yelp_usr_cluster <- yelp_users %>% 
          #select(user_id) %>% 
          mutate(cluster = kmeans_usr$cluster)

yelp_usr_cluster %>% 
  ggplot(aes(year_since,average_stars, color = cluster)) +
  geom_point()

```


```{r}

library(plotly)

plot_ly(yelp_usr_cluster, x = ~year_since, 
               y = ~average_stars,
               z = ~fans, color = ~cluster) %>% 
  add_markers()

```


```{r}

yelp_usr_cluster <- yelp_users %>% 
          select(user_id, cluster) %>%
          write.csv(file = "output/bz_cluster.csv")

```

# Referências

- Neumann, D. Material de aula do cursos Big Data e Computação em Nuvem
- Mendonça, T. Material de aula do curso Modelagem Preditiva Avançada
- [Fernandez, P. Marques. P. Data Science, Marketing and Business](https://datascience.insper.edu.br/datascience.pdf)
- [Rahimi, S.; Mottahedi, S.; Liu, X. The Geography of Taste: Using Yelp to Study Urban Culture. ISPRS Int. J. Geo-Inf. 2018, 7, 376.](https://www.mdpi.com/2220-9964/7/9/376?type=check_update&version=1)
- [Silge, J.](https://juliasilge.com/blog/sherlock-holmes-stm/)




