---
title: "Integradora Yelp"
author: "Marcelo Francheschini, Rafael Costa, Viviane Sanchez"
date: "6/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(tidymodels)
library(tidytext)
library(skimr)
library(ggrepel)
library(ggdendro)
library(factoextra)
library(vip)
library(doParallel)
library(cluster)
library(plotly)

```

```{r}

library(tidytext)
library(tm)
library(wordcloud)
library(topicmodels)
library(drlib)
library(quanteda)
library(stm)

library(keras)
library(reticulate)

```

# Leitura de arquivos individuais

```{r eval=FALSE, include=FALSE}
```


```{r eval=FALSE, include=FALSE}
yelp_bz_raw <- list.files(path = 'output/yelp_bz.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

yelp_users <- list.files(path = 'output/yelp_usr.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

?daisy

```

# Business

Clusterização dos estabelecimentos por semelhança de atributos


```{r}

glimpse(yelp_bz_raw)

yelp_bz <- yelp_bz_raw %>% 
          select_if(~is.numeric(.))
  
```

## Matriz de dissimilaridades

Distância Euclidiana é válida para intervalos contínuos. Como a base possui diferentes atributos, será utilizada a distância de Gower, que é mais apropriada para dados misturados

```{r}

bz_gower <- daisy(yelp_bz, metric = 'gower')

gower_mat <- as.matrix(bz_gower)

dim(gower_mat)

# Output most similar pair
#yelp_bz[which(gower_mat == min(gower_mat[gower_mat != min(gower_mat)]),arr.ind = TRUE)[1, ], ]

# Output most dissimilar pair
#yelp_bz[which(gower_mat == max(gower_mat[gower_mat != max(gower_mat)]), arr.ind = TRUE)[1, ], ]

```

## MDS (lento)

```{r}

mds <- cmdscale(gower_mat, k = 35, eig = TRUE)

?cmdscale

barplot(mds$eig)

cumsum(mds$eig) / sum(mds$eig)

# ggplot(mapping = aes(x = factor(1:length(mds$eig)), y = mds$eig)) +
#     geom_col() +
#     labs(x = "", y = "")

hc <- hclust(dist(mds$points[, 1:2]))

ggdendrogram(hc, rotate = TRUE, size = 2, labels = TRUE) +
    labs(title = "Concorrência no mercado automobilístico")

cutree(hc, k = 3)



```


## HCLUST

```{r}
## Hclust

bz_hclust <- hclust(bz_gower)

clust <- cutree(hclust, k = 10)

ggdendrogram(hclust, rotate = TRUE, labels = TRUE) +
    labs(title = "Categorias em Toronto - Gower")

fviz_dend(hclust, cex = 0.5, k = 5,
          main = "Categorias em Toronto - Euclidiana",
          color_labels_by_k = TRUE, horiz = TRUE)


yelp_bz_clust <- yelp_bz_raw %>% 
                mutate(cluster = clust)


yelp_bz_clust %>% 
  ggplot(aes(longitude,latitude, color = cluster)) +
           geom_point()

```


## PCA

```{r}

yelp_bz_pca <-  yelp_bz_raw %>% 
                select_if(~is_numeric(.))
  
rec_pca <- recipe(stars ~ ., yelp_bz_pca) %>% 
  update_role(contains('id'), new_role = 'id') %>% 
  #step_date(date_rv, yelping_since_usr, features = c("dow", "month","year")) %>% 
  #step_other(categories, threshold = 0.005) %>% 
  #step_other(postal_code, threshold = 0.01) %>% 
  #step_dummy(all_nominal(), -'business_id',-'user_id',-'name_bz') %>%
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_pca(all_numeric(), -all_outcomes()) %>% 
  step_naomit(all_numeric()) %>% 
  prep()

yelp_bz_pca <- juice(rec_pca)

```


```{r}

variance_pct <- rec_pca$steps[[2]]$res

(cumsum(variance_pct$sdev^2) / sum(variance_pct$sdev^2))

fviz_eig(variance_pct, addlabels = TRUE) + 
  labs(x = "Componente Principal",
       y = "Percentual explicado da variância")

```


```{r}

tidy_pca <- tidy(rec_pca, 2)

tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(5, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Valor absoluto da contribuição",
    y = NULL, fill = "Positiva?")

variance_pct %>% 
  fviz_pca_var(axes = c(1,2), col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

pca_cols <- tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(1, abs(value)) %>%
  ungroup() %>% 
  select(terms) %>% 
  as.vector()

```

## K-means

```{r}

glimpse(yelp_bz_raw)

?kmeans

skim(yelp_bz)

set.seed(123)

kclusts <- tibble(k = 1:50) %>%
  mutate(kclust = map(k, ~kmeans(yelp_bz, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_bz)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))


#cotovelo
clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:50)


#k-means
assignments %>% 
  ggplot(aes(x = longitude, y = latitude)) +
  geom_point(aes(color = .cluster), alpha = 0.5) + 
  facet_wrap(~ k)

```


```{r}

set.seed(123)
kmeans_bz <-  kmeans(yelp_bz, 10)

yelp_bz_cluster <- yelp_bz_raw %>% 
          select(business_id) %>% 
          mutate(cluster = kmeans_bz$cluster)


write.csv(yelp_bz_cluster, file = "output/bz_cluster.csv")

```

# Users
## KMeans

```{r}

set.seed(123)

yelp_pad <- yelp_users %>% 
              select(-user_id) %>% 
              scale()

kclusts <- tibble(k = 1:20) %>%
  mutate(kclust = map(k, ~kmeans(yelp_pad, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_pad)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))

clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:20)


```

```{r}

set.seed(123)
kmeans_usr <-  kmeans(yelp_pad, 7)

yelp_usr_cluster <- yelp_users %>% 
          #select(user_id) %>% 
          mutate(cluster = kmeans_usr$cluster)

glimpse(yelp_usr_cluster)

```


```{r}

plot_ly(yelp_usr_cluster, x = ~year_since, 
               y = ~average_stars,
               z = ~fans, color = ~cluster) %>% 
  add_markers()



```


```{r}

yelp_usr_cluster %>% 
          select(user_id, cluster) %>%
          write.csv(file = "output/usr_cluster.csv")

```




## Rede Neural

Leitura da base final

```{r}

yelp_raw <- list.files(path = 'output/yelp.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

skim(yelp_raw)

```



```{r}

yelp_rv <- yelp_raw %>% 
  #mutate(line = row_number()) %>% 
  select(-'cool',-'date',-'funny',-'useful',-'cluster_usr') %>% 
  mutate(stars = replace(stars >= 4,1,0)) %>% 
  select_if(is.numeric) #%>% sample_frac(0.50)

glimpse(yelp_rv)

```


```{r}

set.seed(123)

idx <- sample(c(1, 2, 3), size = nrow(yelp_rv), replace = TRUE)
  
x_tr <- select(yelp_rv[idx == 1, ], -stars) %>% 
          scale() %>% 
          as.matrix()

y_tr <- as.numeric(yelp_rv$stars[idx == 1])


x_val <- select(yelp_rv[idx == 2, ], -stars) %>%
          scale() %>% 
          as.matrix()

y_val <- as.numeric(yelp_rv$stars[idx == 2])


x_test <- select(yelp_rv[idx == 3, ], -stars) %>% 
          scale() %>% 
          as.matrix()

y_test <- as.numeric(yelp_rv$stars[idx == 3])

```


```{r}

rm(yelp_nn)

yelp_nn <- keras_model_sequential() %>% 
  layer_dense(units = 30, activation = "tanh", input_shape = ncol(x_tr)) %>%
  layer_dense(units = 15, activation = "relu") %>%
  layer_dense(units = 5, activation = "relu") %>%
  #layer_dense(units = 6, activation = "softmax")
  layer_dense(units = 1, activation = "sigmoid")


?keras_model_sequential

yelp_nn %>% 
  compile(optimizer = "rmsprop", 
          #loss = "sparse_categorical_crossentropy", 
          loss = "binary_crossentropy",
          metrics = c("accuracy"))


history <- yelp_nn %>% 
  fit(x_tr, y_tr, 
      epochs = 80, batch_size = 512, 
      validation_data = list(x_val, y_val))

keras::get_weights(yelp_nn)

results <- yelp_nn %>% evaluate(x_test, y_test)


#probabilidade de ser um bom review
predictions <- yelp_nn %>% 
              predict(x_test)

```


```{r}

tibble(observado = factor(y_test)) %>% 
  bind_cols(data.frame(prob = predict(yelp_nn, as.matrix(x_test)))) %>% 
  roc_auc(observado, prob)

tibble(observado = factor(y_test)) %>% 
  bind_cols(data.frame(prob = predict(yelp_nn, as.matrix(x_test)))) %>% 
  roc_curve(observado, prob) %>% 
  autoplot()

```

# Recomendação

Seleção do usário

```{r}

user <- yelp_raw[5,]$user_id

user_cluster <- yelp_usr_cluster %>% 
  filter(user_id == user)

yelp_users %>% 
   filter(user_id == user)

## predict cluster do usuário
user <- yelp_users %>% 
   filter(user_id == user)
kmeans_usr %>% 
  predict(user)

reviewed <- yelp_raw %>% 
  filter(user_id == user)

skim(reviewed)

to_go <-yelp_raw %>% 
  filter(cluster_usr == user_cluster$cluster)


```


```{r}

id <- yelp_raw[5,]$user_id

recommendation <- function(id){
  
  user <- yelp_users %>% 
   filter(user_id == id)
  
  #predict do cluster
  
  user_cluster <- yelp_usr_cluster %>% 
              filter(user_id == user$user_id) %>% 
              select(cluster)
  
  
  yelp_rv <- yelp_raw %>% 
  #mutate(line = row_number()) %>% 
  select(-'cool',-'date',-'funny',-'useful',-'cluster_usr') %>% 
  mutate(stars = replace(stars >= 4,1,0)) %>% 
  select_if(is.numeric)
  
  reviewed <- yelp_raw %>% 
        filter(user_id == id) %>% 
        select(-'cool',-'date',-'funny',-'useful',-'cluster_usr') %>% 
        mutate(stars = replace(stars >= 4,1,0)) %>% 
        select_if(is.numeric)
  
  to_go <- yelp_raw %>% 
    filter(cluster_usr == user_cluster$cluster) %>% 
    select(business_id) %>% 
    distinct()
    
  
    select(-'cool',-'date',-'funny',-'useful',-'cluster_usr') %>% 
    mutate(stars = replace(stars >= 4,1,0)) %>% 
    select_if(is.numeric)

  
  to_review <-  reviewed %>% 
    bind_rows(to_go)
  
  
tail(to_review)
    
  # juntar linhas dos restaurantes a serem avaliados

    
  glimpse(to_go)
  
  user_x_test <- select(to_review, -stars) %>% 
          scale() %>% 
          as.matrix()

  user_y_test <- as.numeric(to_review$stars)
  
  results <- yelp_nn %>% 
    evaluate(user_x_test, user_y_test)
  
  predictions <- yelp_nn %>% 
              predict(user_x_test)
  
  
  
}




```




# Referências

- Neumann, D. Material de aula do cursos Big Data e Computação em Nuvem
- Mendonça, T. Material de aula do curso Modelagem Preditiva Avançada
- [Fernandez, P. Marques. P. Data Science, Marketing and Business](https://datascience.insper.edu.br/datascience.pdf)
- [Rahimi, S.; Mottahedi, S.; Liu, X. The Geography of Taste: Using Yelp to Study Urban Culture. ISPRS Int. J. Geo-Inf. 2018, 7, 376.](https://www.mdpi.com/2220-9964/7/9/376?type=check_update&version=1)
- [Silge, J.](https://juliasilge.com/blog/sherlock-holmes-stm/)
https://www.datanovia.com/en/lessons/clustering-distance-measures/



