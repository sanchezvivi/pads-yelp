---
title: "Integradora Yelp"
author: "Marcelo Francheschini, Rafael Costa, Viviane Sanchez"
date: "6/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(tidymodels)
library(tidytext)
library(skimr)
library(ggrepel)
library(ggdendro)
library(factoextra)
library(vip)
library(doParallel)
library(cluster)
library(plotly)

```

```{r}

library(tidytext)
library(tm)
library(wordcloud)
library(topicmodels)
library(drlib)
library(quanteda)
library(stm)

library(keras)
library(reticulate)

```

# Leitura de arquivos individuais

```{r eval=FALSE, include=FALSE}
```


```{r eval=FALSE, include=FALSE}
yelp_bz_raw <- list.files(path = 'output/yelp_bz.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

yelp_users <- list.files(path = 'output/yelp_usr.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

```

# Business

Clusterização dos estabelecimentos por semelhança de atributos

```{r}

glimpse(yelp_bz_raw)

yelp_bz <- yelp_bz_raw %>% 
          select_if(~is.numeric(.))
  
```

## PCA

Será aplicada uma análise de componentes principais para entender a variabilidade da nota dos estabelecimentos considerando seus atributos.

```{r}
  
rec_pca <- recipe(stars ~ ., yelp_bz) %>% 
  update_role(contains('id'), new_role = 'id') %>% 
  #step_date(date_rv, yelping_since_usr, features = c("dow", "month","year")) %>% 
  #step_other(categories, threshold = 0.005) %>% 
  #step_other(postal_code, threshold = 0.01) %>% 
  #step_dummy(all_nominal(), -'business_id',-'user_id',-'name_bz') %>%
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_pca(all_numeric(), -all_outcomes()) %>% 
  step_naomit(all_numeric()) %>% 
  prep()

yelp_bz_pca <- juice(rec_pca)

```

### Scree plot

```{r}

variance_pct <- rec_pca$steps[[2]]$res

(cumsum(variance_pct$sdev^2) / sum(variance_pct$sdev^2))

fviz_eig(variance_pct, addlabels = TRUE) + 
  labs(x = "Componente Principal",
       y = "Percentual explicado da variância")

```

Mais de 50% da variabilidade é explicada pelas 5 primeiras componentes, que são compostas da seguinte forma:

### Drivers

```{r}

tidy_pca <- tidy(rec_pca, 2)

tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(10, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Valor absoluto da contribuição",
    y = NULL, fill = "Positiva?")


```

Na primeira componente, os pesos são igualmente distribuídos, o que indica ........

Pela segunda componentem observa-se que a existência de um local para deixar o casaco e ser permitido fumar melhoram a nota do estabelecimento, assim como a localização e possibilidade de fazer reservas.
Por outro lado, cobrança de rolha e necessidade de levar a bebida, possuem impactos negativos na nota.

## Contrastes

```{r}

variance_pct %>% 
  fviz_pca_var(axes = c(1,2), col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))


```

Os maiores contrastes são entre..........

## K-means

```{r}

glimpse(yelp_bz_raw)

?kmeans

skim(yelp_bz)

set.seed(123)

kclusts <- tibble(k = 1:50) %>%
  mutate(kclust = map(k, ~kmeans(yelp_bz, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_bz)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))


#cotovelo
clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:50)

```

```{r}

set.seed(123)
kmeans_bz <-  kmeans(yelp_bz, 10)

yelp_bz_cluster <- yelp_bz_raw %>% 
          select(business_id) %>% 
          mutate(cluster = kmeans_bz$cluster)


write.csv(yelp_bz_cluster, file = "output/bz_cluster.csv")

```

# Users

Classificação dos usuários conforme o perfil.

## KMeans

```{r}

set.seed(123)

glimpse(yelp_users)

yelp_pad <- yelp_users %>% 
              select(-user_id) %>% 
              scale()

kclusts <- tibble(k = 1:30) %>%
  mutate(kclust = map(k, ~kmeans(yelp_pad, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_pad)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))

```

```{r}

### Cotovelo

clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:30)

```

```{r}

#k-means
assignments %>% 
  ggplot(aes(x = year_since, y = average_stars)) +
  geom_point(aes(color = .cluster), alpha = 0.5) + 
  facet_wrap(~ k)

```


```{r}

set.seed(123)
kmeans_usr <-  kmeans(yelp_pad, 11)

yelp_usr_cluster <- yelp_users %>% 
          mutate(cluster = kmeans_usr$cluster)

```


Pelo gráfico, observa-se claramente a divisão dos usuários em relação ao tempo na plataforma, a nota média e a quantidade de fãs.

```{r}

plot_ly(yelp_usr_cluster, x = ~year_since, 
               y = ~average_stars,
               z = ~fans, color = ~cluster,
              text = ~paste('Cluster: ', cluster)) %>% 
  add_markers() %>% 
  layout(scene = list(xaxis = list(title = 'No Yelp desde'),
                                   yaxis = list(title = 'Nota Média'),
                                   zaxis = list(title = 'Quantidade de fãs')))

```


```{r}

yelp_usr_cluster %>% 
          select(user_id, cluster) %>%
          write.csv(file = "output/usr_cluster.csv")

```

## Modelo para definição do cluster do usuário

```{r}

library(rpart)
library(partykit) 

user_cluster_tree <- yelp_usr_cluster %>% 
                    select(-user_id) %>% 
                    rpart(cluster ~ ., data = .)

plot_arvore <- as.party(user_cluster_tree)

plot(plot_arvore)

```


## Rede Neural

### Treino do modelo
Leitura da base final

```{r}

yelp_raw <- list.files(path = 'output/yelp.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))
glimpse(yelp_raw)

```


```{r}

yelp_rv <- yelp_raw %>% 
  #mutate(line = row_number()) %>% 
  select(-'year_rv') %>% 
  mutate(stars_rv = replace(stars_rv >= 4,1,0)) %>% 
  select_if(is.numeric) #%>% sample_frac(0.50)

glimpse(yelp_rv)

```


```{r}

set.seed(123)

idx <- sample(c(1, 2, 3), size = nrow(yelp_rv), replace = TRUE)
  
x_tr <- select(yelp_rv[idx == 1, ], -stars_rv) %>% 
          #scale() %>% 
          as.matrix()

y_tr <- as.numeric(yelp_rv$stars_rv[idx == 1])


x_val <- select(yelp_rv[idx == 2, ], -stars_rv) %>%
          #scale() %>% 
          as.matrix()

y_val <- as.numeric(yelp_rv$stars_rv[idx == 2])


x_test <- select(yelp_rv[idx == 3, ], -stars_rv) %>% 
          #scale() %>% 
          as.matrix()

y_test <- as.numeric(yelp_rv$stars_rv[idx == 3])

```

```{r}

rm(yelp_nn)

yelp_nn <- keras_model_sequential() %>% 
  layer_dense(units = 30, activation = "tanh", input_shape = ncol(x_tr)) %>%
  layer_dense(units = 15, activation = "relu") %>%
  layer_dense(units = 5, activation = "relu") %>%
  #layer_dense(units = 6, activation = "softmax")
  layer_dense(units = 1, activation = "sigmoid")


?keras_model_sequential

yelp_nn %>% 
  compile(optimizer = "rmsprop", 
          #loss = "sparse_categorical_crossentropy", 
          loss = "binary_crossentropy",
          metrics = c("accuracy"))


history <- yelp_nn %>% 
  fit(x_tr, y_tr, 
      epochs = 80, batch_size = 512, 
      validation_data = list(x_val, y_val))

keras::get_weights(yelp_nn)

results <- yelp_nn %>% evaluate(x_test, y_test)


#probabilidade de ser um bom review
predictions <- yelp_nn %>% 
              predict(x_test)


dim(x_test)

```


```{r}

tibble(observado = factor(y_test)) %>% 
  bind_cols(data.frame(prob = predict(yelp_nn, as.matrix(x_test)))) %>% 
  roc_auc(observado, prob)

tibble(observado = factor(y_test)) %>% 
  bind_cols(data.frame(prob = predict(yelp_nn, as.matrix(x_test)))) %>% 
  roc_curve(observado, prob) %>% 
  autoplot()

```

# Recomendação

Criação de um usuário e definição de seu cluster

```{r}

rm(user)

compliment_max <- 15

user <- tibble(user_id = 'random_user',
               average_stars = round(runif(1, 1.0, 5),2),
               compliment_cool = ceiling(runif(1,0, compliment_max)),
               compliment_cute = ceiling(runif(1,0, compliment_max)),
               compliment_funny = ceiling(runif(1,0, compliment_max)),
               compliment_hot  = ceiling(runif(1,0, compliment_max)),
               compliment_list = ceiling(runif(1,0, compliment_max)),
               compliment_more = ceiling(runif(1,0, compliment_max)),
               compliment_note = ceiling(runif(1,0, compliment_max)),
               compliment_photos = ceiling(runif(1,0, compliment_max)),
               compliment_plain = ceiling(runif(1,0, compliment_max)),
               compliment_profile = ceiling(runif(1,0, compliment_max)),
               compliment_writer = ceiling(runif(1,0, compliment_max)),
               cool = ceiling(runif(1,0, compliment_max)),
               elite_count = 0,
               fans = ceiling(runif(1,0, compliment_max)),
               friends_count = ceiling(runif(1,0, compliment_max)),
               funny = ceiling(runif(1,0, compliment_max)),
               review_count_usr = ceiling(runif(1,0,compliment_max)),
               useful = ceiling(runif(1,0, compliment_max)),
               year_since = ceiling(runif(1,2009, 2019))
                )

## criação aleatória do número de anos que o usuário foi elite
user$elite_count <- ceiling(runif(1,0, (2020-user$year_since)))


#encontra o número do cluster em que o usuário se encaixa
user$cluster_usr <- user_cluster_tree %>%
      predict(user) %>% 
      ceiling()
  
# seleção aleatória de estabelecimentos e notas atribuídas a cada um baseado no número de reviews

n_reviews <- user$review_count_usr

reviewed_usr <- tibble(business_id = sample(yelp_bz_raw$business_id, n_reviews),
                                            stars_rv = ceiling(runif(n_reviews, 1.0, 5)),
                                            year_rv = ceiling(runif(n_reviews, 2009, 2019)),
                                            )
user_hist <- user %>% 
            bind_rows(replicate(n_reviews-1, user, simplify = FALSE)) %>% #replica as informações do usuário
            bind_cols(reviewed_usr) %>% #junta os estabelecimentos e notas dadas
            left_join(., yelp_bz_raw, by = 'business_id') #junta as informações dos estabelecimentos

glimpse(user_hist)


```


```{r}

library(zoo)

to_go <- yelp_raw %>% 
  filter(stars >= 4) %>% 
  filter(cluster_usr == user$cluster_usr) %>% 
  select(business_id) %>% 
  distinct() %>% 
  left_join(., yelp_bz_raw, by = 'business_id')

to_review <- user_hist %>% 
             bind_rows(to_go) %>% 
             na.locf.default() #preenche linhas vazias com informação do usuário

?fill

skim(to_review)

```

```{r}

recommendation <- function(user, reviewed_usr){
  
  to_go <- yelp_raw %>% 
    filter(stars_rv >= 4) %>% 
    filter(cluster_usr == user$cluster_usr) %>% 
    select(business_id) %>% 
    distinct() # %>% 
    #left_join(., yelp_bz_raw, by = 'business_id')
  
  n_go <- nrow(to_go)
  
  to_review <- user %>% 
            bind_rows(replicate(n_go-1, user, simplify = FALSE)) %>% #replica as informações do usuário
            bind_cols(to_go) %>% #junta os estabelecimentos e notas dadas
            left_join(., yelp_bz_raw, by = 'business_id')

  
user_x_test <- to_review %>% 
          select_if(is.numeric) %>% 
          #select(-stars_rv) %>% 
          #scale() %>% 
          as.matrix() 

predictions <- as_tibble(predict(yelp_nn, user_x_test))

  recommendation <- to_review %>% 
    bind_cols(pred = predictions) %>% 
    anti_join(., reviewed_usr, by = 'business_id')

}

tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Valor absoluto da contribuição",
    y = NULL, fill = "Positiva?")



```

```{r}

#top 5 recomendações por categoria

  recommendation %>% 
    filter(V1 > 0.5) %>% 
    #group_by(categories) %>% 
    top_n(5, V1) %>%
    arrange(-V1) %>% 
    #ungroup() %>%
    #mutate(name = reorder_within(name, V1)) %>%
    ggplot(aes(x = V1, y = name)) +
    geom_col() +
    #facet_wrap(~categories, scales = "free_y") +
    #scale_y_reordered() +
    labs(x = "Probabilidade de avaliação positiva",
    y = 'Recomendação')



    


```

```{r}

library(leaflet)

m <- leaflet() %>%
  addTiles() %>%  # Add default OpenStreetMap map tiles
  addMarkers(lng=174.768, lat=-36.852, popup="The birthplace of R")
m 

Í#mapa com as top 5 recomendações
  
  recommendation %>% 
    filter(V1 > 0.5) %>% 
    top_n(5, V1) %>%
    arrange(V1) %>% 
    mutate(rank = as.factor(row_number())) %>% 
    #select(name, longitude, latitude)
    ggplot(aes(x = longitude, y = latitude, color = rank)) +
    geom_point()+
    geom_text_repel(aes(label = name), size = 3)


```


# Referências

- Neumann, D. Material de aula do cursos Big Data e Computação em Nuvem
- Mendonça, T. Material de aula do curso Modelagem Preditiva Avançada
- [Fernandez, P. Marques. P. Data Science, Marketing and Business](https://datascience.insper.edu.br/datascience.pdf)
- [Rahimi, S.; Mottahedi, S.; Liu, X. The Geography of Taste: Using Yelp to Study Urban Culture. ISPRS Int. J. Geo-Inf. 2018, 7, 376.](https://www.mdpi.com/2220-9964/7/9/376?type=check_update&version=1)
- [Silge, J.](https://juliasilge.com/blog/sherlock-holmes-stm/)
https://www.datanovia.com/en/lessons/clustering-distance-measures/



