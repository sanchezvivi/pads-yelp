---
title: "Integradora Yelp"
author: "Marcelo Francheschini, Rafael Costa, Viviane Sanchez"
date: "6/27/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)
library(tidymodels)
library(tidytext)
library(skimr)
library(ggrepel)
library(ggdendro)
library(factoextra)
library(vip)
library(doParallel)
library(leaps)

library(tidytext)
library(tm)
library(wordcloud)
library(topicmodels)
#library(drlib)
library(quanteda)
library(stm)


```


## Leitura de arquivos

```{r eval=FALSE, include=FALSE}

yelp_raw <- list.files(path = 'output/yelp.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))


yelp_dist_raw <- list.files(path = 'output/yelp_dist.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))

yelp_words <- list.files(path = 'output/yelp_words.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))


yelp_users <- list.files(path = 'output/yelp_usr.csv/', 
                       pattern = "*.csv",
                       full.names = TRUE) %>% 
            map_df(~read_csv(.))


#view(yelp_users)
```


## Análise da Base de Usuários

```{r}

##########  Hierarchical Clustering - Dist Euclidiana  ##########
# Preparando a Base

yelp_usr_euc <- t(yelp_users[,-c(1)])

euc_usr_hclust <- (hclust(get_dist(t(yelp_usr_euc), method = 'euclidean')))

```



```{r}
##########   Hierarchical Clustering - Dist Euclidiana    ##########
# Gráficos

ggdendrogram(euc_usr_hclust, rotate = TRUE, labels = TRUE) +
    labs(title = "Categorias em Toronto - Euclidiana")

fviz_dend(euc_usr_hclust , cex = 0.5, k = 6,
          main = "Categorias de Usuários - Euclidiana",
          color_labels_by_k = TRUE, horiz = TRUE)


# Cortar A clusterização com base no número de clusters
user_euc_clust <- cutree(euc_usr_hclust , k = 6)

view(user_euc_clust)

```


```{r}

yelp_pad <- yelp_users %>% 
              select(-user_id) %>% 
              scale() 

kclusts <- tibble(k = 1:20) %>%
  mutate(kclust = map(k, ~kmeans(yelp_pad, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_pad)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))

clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:20)

```


```{r}

set.seed(123)

kmeans_usr <-  kmeans(yelp_pad, 7)

yelp_usr_cluster <- yelp_users %>% 
          #select(user_id) %>% 
          mutate(cluster = kmeans_usr$cluster)

yelp_usr_cluster %>% 
  ggplot(aes(year_since,average_stars, color=cluster))+
  geom_point()

library(plotly)

fig <- plot_ly(yelp_usr_cluster, x = ~year_since, 
               y = ~average_stars,
               z = ~fans, color = ~cluster)

fig <- fig %>% add_markers()

fig <- fig %>% layout(scene = list(xaxis = list(title = 'Yelping since'),
                                   range = c('2000-01-01','2020-01-01'),
                     yaxis = list(title = 'User Score'),
                     zaxis = list(title = 'Review Stars')))

fig

#write.csv(yelp_bz_cluster, file = "output/bz_cluster.csv")

```







## Análise de reviews e tips

[FONTE](https://juliasilge.com/blog/sherlock-holmes-stm/)

```{r}

yelp_corpus <- yelp_words %>% 
  #select(review_tip) %>% 
  mutate(line = row_number()) %>% 
  unnest_tokens(word, review_tip) %>% 
  anti_join(stop_words) %>% 
  filter(!word %in% c(0,1,2,3,4,5,6,7,8,9)) %>% 
  filter(!word %in% c('food','service','time','restaurant'))
  
  
glimpse(stop_words)

yelp_corpus %>%
    count(word, sort = TRUE)

```


### Wordcloud
Palavras mais utilizadas nas reviews boas:
```{r}

corpus %>% 
  filter(stars >= 4 ) %>% 
  filter(!word %in%  c('food','service')) %>% 
  count(word, sort = TRUE) %>% 
  top_n(100, n) %>% 
  with(wordcloud(word, n, random.order = FALSE, 
       colors = brewer.pal(8, "Dark2")))
```


Palavras mais utilizadas nas reviews não boas:
```{r}

corpus %>% 
  filter(stars < 4 ) %>% 
  filter(!word %in%  c('food','service')) %>% 
  count(word, sort = TRUE) %>% 
  top_n(100, n) %>% 
  with(wordcloud(word, n, random.order = FALSE, 
       colors = brewer.pal(8, "Dark2")))

```


## Modelo de tópicos

### Frequência
```{r}

yelp_tf_idf <- yelp_corpus %>%
    count(stars, word, sort = TRUE) %>%
    bind_tf_idf(word, stars, n) %>%
    arrange(-tf_idf) %>%
    group_by(stars) %>%
    top_n(10) %>%
    ungroup

yelp_tf_idf %>%
    mutate(word = reorder_within(word, tf_idf, stars)) %>%
    ggplot(aes(word, tf_idf, fill = stars)) +
    geom_col(alpha = 0.8, show.legend = FALSE) +
    facet_wrap(~stars, scales = "free") +
    scale_x_reordered() +
    coord_flip() +
    #theme(strip.text=element_text(size=11)) +
    labs(x = NULL, y = "tf-idf",
         title = "Highest tf-idf words by review stars"
         #subtitle = "Individual stories focus on different characters and narrative elements"
         )

```

### Modelo de tópicos
```{r}

yelp_dfm <- yelp_corpus %>%
    count(stars, word, sort = TRUE) %>%
    cast_dfm(stars, word, n)

topic_model <- stm(yelp_dfm, K = 5, 
                   verbose = FALSE, init.type = "Spectral")

yelp_sparse <- yelp_corpus %>%
    count(stars, word, sort = TRUE) %>%
    cast_sparse(stars, word, n)

topic_model_sparse <- stm(yelp_sparse, K = 5, 
                   verbose = FALSE, init.type = "Spectral")

td_beta <- tidy(topic_model)

td_beta_sparse <- tidy(topic_model_sparse)

td_beta_sparse %>%
    group_by(topic) %>%
    top_n(10, beta) %>%
    ungroup() %>%
    mutate(topic = paste0("Topic ", topic),
           term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta, fill = as.factor(topic))) +
    geom_col(alpha = 0.8, show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free_y") +
    coord_flip() +
    scale_x_reordered() +
    labs(x = NULL, y = expression(beta),
         title = "Highest word probabilities for each topic",
         subtitle = "Same words are associated with different topics")


```

### Probabilidades do documento para cada tópico

```{r}


td_gamma <- tidy(topic_model, matrix = "gamma",                    
                 document_names = rownames(yelp_dfm))

ggplot(td_gamma, aes(gamma, fill = as.factor(topic))) +
  geom_histogram(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~ topic, ncol = 3) +
  labs(title = "Distribution of document probabilities for each topic",
       subtitle = "Each topic is associated with 1-3 stars",
       y = "Number of stars", x = expression(gamma))


```


# Clusters
## yelp - dist

```{r}

##########  Hierarchical Clustering - Dist Euclidiana  ##########
# Preparando a Base

yelp_euc <- yelp_dist_raw %>%
        select(-business_id, -Food, - Restaurants) %>% 
        select_if(colSums(.) != 0) %>% 
        mutate_all(~replace(., is.na(.), 0)) %>% 
        as.matrix()

euc_hclust <- (hclust(get_dist(t(yelp_euc), method = 'euclidean')))

```


```{r}

##########  Hierarchical Clustering - Dist Jaccard  ##########
# Preparando a Base

yelp_jaccard <- yelp_dist_raw %>%
        select(-business_id, -Food, - Restaurants) %>% 
        select_if(colSums(.) != 0) %>%
        mutate_all(~replace(., is.na(.), 0)) %>% 
        mutate_all(., ~replace(. >= 3, 1,0)) %>% 
        #mutate(user_id = yelp_dist_raw$user_id) %>% 
        as.matrix()

jac_hclust <- hclust(get_dist(t(yelp_jaccard), method = 'binary'))

view(yelp_jaccard)

```


```{r}

##########   Hierarchical Clustering - Dist Euclidiana    ##########
# Gráficos

ggdendrogram(euc_hclust, rotate = TRUE, labels = TRUE) +
    labs(title = "Categorias em Toronto - Euclidiana")

fviz_dend(euc_hclust, cex = 0.5, k = 80,
          main = "Categorias em Toronto - Euclidiana",
          color_labels_by_k = TRUE, horiz = TRUE)


# Cortar A clusterização com base no número de clusters
euc_clust <- cutree(euc_hclust, k = 80)

view(euc_clust)


```

```{r}

##########  Hierarchical Clustering - Dist Jaccard  ##########
# Gráficos

ggdendrogram(jac_hclust, rotate = TRUE, labels = TRUE, color = order) +
    labs(title = "Categorias em Toronto - Jaccard")


fviz_dend(jac_hclust, cex = 0.5, k = 80,
          main = "Categorias em Toronto",
          color_labels_by_k = TRUE, horiz = TRUE) + 
          theme_void()

# Cortar A clusterização com base no número de clusters
jc_clust <- cutree(jac_hclust, k = 80)

view(jc_clust)

```



```{r}
##### Base com duas Distancias 

distancias <- data.frame(euc_clust, jc_clust)
view(distancias)

write.csv(distancias,"C:\\Users\\Rafael\\Documents\\GitHub\\pads-yelp\\output\\Distancias.csv", row.names = TRUE)

```



```{r}

yelp_pad <- yelp_dist_raw %>% 
              select(-business_id) %>% 
              scale() 

kclusts <- tibble(k = 1:150) %>%
  mutate(kclust = map(k, ~kmeans(yelp_pad, .x)),
        tidied = map(kclust, tidy),
        glanced = map(kclust, glance),
        augmented = map(kclust, augment, yelp_pad)
        )

clusters <- kclusts %>%
  unnest(cols = c(tidied))

assignments <- kclusts %>% 
  unnest(cols = c(augmented))

clusterings <- kclusts %>%
  unnest(cols = c(glanced))

clusterings %>% 
  ggplot(aes(k, tot.withinss)) + 
    geom_point(size = 3) + 
    geom_line() + 
    labs(y = "total within sum of squares", x = "k") +
    scale_x_continuous(breaks = 1:150)

```


## Kmedias

```{r}

yelp_matrix <- yelp_juice %>% 
  drop_na() %>% 
  select(-user_id, -business_id, -name_bz, -date, -yelping_since) %>% 
  as.matrix()

kclust <- kmeans(yelp_matrix, 5)

summary(kclust)

kclusts <- 
  tibble(k = 1:9) %>%
  mutate(
    kclust = map(k, ~kmeans(yelp_matrix, .x)),
    tidied = map(kclust, tidy),
    glanced = map(kclust, glance),
    augmented = map(kclust, augment, points)
  )

```


```{r}

    yelp_hclust <- yelp_matrix %>%
        get_dist(method = "euclidean")
    
        #hclust(method = "complete")

    
       yelp_hclust <- yelp_juice %>%
        select(-user_id, -business_id, -date, -yelping_since) %>% 
        get_dist(method = "manhattan") %>%  
        hclust(method = "complete")


```



## Yelp -  base completa 

```{r}

skim(yelp_raw)

yelp <- yelp_raw %>% 
        mutate(yelping_since = as.Date(yelping_since),
         date = as.Date(date))
  

skim(yelp)

```


### Latitude vs Longitude

```{r}

gg_lat_lon <- function(col_ref, title_string){
      yelp %>% 
        ggplot(aes(longitude, latitude, color = col_ref)) +
        geom_point(size = 0.5, alpha = 0.7) +
        scale_color_gradient(low = 'skyblue', high = 'gold', labels = scales::label_number_si()) +
        labs(title = title_string)
}

```

```{r}

gg_lat_lon(yelp$stars_usr, 'Average Stars by user')

```

```{r}

gg_lat_lon(yelp$stars, 'Review Stars')

```

```{r}

gg_lat_lon(yelp$stars_bz, 'Average Stars by Business')

```

```{r}

gg_lat_lon(yelp$review_count, 'Review count by Business')

```


### Split

```{r}

split <- initial_split(yelp, prop = 0.8)

train <- training(split)
test <- testing(split)

```


### Recipe

```{r}

rec <- recipe( ~ ., train) %>% 
  update_role(business_id, user_id, name_bz, new_role = 'id') %>% 
  step_date(date, yelping_since, features = c("dow", "month","year")) %>% 
  step_other(categories, threshold = 0.005) %>% 
  step_other(postal_code, threshold = 0.01) %>% 
  step_dummy(all_nominal(), -'business_id',-'user_id',-'name_bz') %>%
  step_normalize(all_numeric()) %>% 
  step_naomit(all_predictors())

yelp_juice <- juice(prep(rec))

skim(yelp_juice)

```



### PCA

```{r}

rec_pca <- recipe( ~ ., train) %>% 
  update_role(business_id, user_id, name_bz, new_role = 'id') %>% 
  step_date(date, yelping_since, features = c("dow", "month","year")) %>% 
  #step_other(categories, threshold = 0.005) %>% 
  #step_other(postal_code, threshold = 0.01) %>% 
  #step_dummy(all_nominal(), -'business_id',-'user_id',-'name_bz') %>%
  step_normalize(all_numeric()) %>% 
  step_pca(all_numeric()) %>% 
  step_naomit(all_predictors()) %>% 
  prep()


yelp_pca <- juice(rec_pca)

skim(yelp_pca)

#pca_train  <- juice(rec_pca) 

rec_pca$steps[[3]]$res

  
```


### Scree Plot

```{r}

variance_pct <- rec_pca$steps[[3]]$res

(cumsum(variance_pct$sdev^2) / sum(variance_pct$sdev^2))

fviz_eig(variance_pct, addlabels = TRUE) + 
  labs(x = "Componente Principal",
       y = "Percentual explicado da variância")

```

### Componentes Principais

```{r}

tidy_pca <- tidy(rec_pca, 3)

tidy_pca %>% 
  filter(component %in% paste0("PC", 1:5)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component) +
  labs(y = NULL)

```


### Principais contribuições

```{r}

tidy_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  group_by(component) %>%
  top_n(8, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Valor absoluto da contribuição",
    y = NULL, fill = "Positiva?")

```


## Contrastes

```{r}

variance_pct %>% 
  fviz_pca_var(axes = c(1,2), col.var="contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```


# Referências

- Neumann, D. Material de aula do cursos Big Data e Computação em Nuvem
- Mendonça, T. Material de aula do curso Modelagem Preditiva Avançada
- [Fernandez, P. Marques. P. Data Science, Marketing and Business](https://datascience.insper.edu.br/datascience.pdf)
- [Rahimi, S.; Mottahedi, S.; Liu, X. The Geography of Taste: Using Yelp to Study Urban Culture. ISPRS Int. J. Geo-Inf. 2018, 7, 376.](https://www.mdpi.com/2220-9964/7/9/376?type=check_update&version=1)
- [Silge, J.](https://juliasilge.com/blog/sherlock-holmes-stm/)




